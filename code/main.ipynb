{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2178,"status":"ok","timestamp":1721059544898,"user":{"displayName":"April Yan","userId":"09852906434199162721"},"user_tz":240},"id":"RyimwfkBtMdH","outputId":"82b0fd20-1191-4ce5-ec29-cdd0fcb2b1c4"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","from train import *\n","from preprocess import *\n","from utils import *\n","\n","import tensorflow as tf\n","from keras.optimizers import RMSprop"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_path = '../train_data/'   # change data path accordingly\n","features_path = '../feature/'\n","patients = [user + '/' for user in sorted(os.listdir(data_path)) if user[0].isalpha()]\n","splits = ['train/', 'val/', 'test/']\n","labels = ['relapse/','non-relapse/', '']\n","file_name = '/data.csv'\n","\n","patient = patients[0]\n","split = splits[-1]\n","label = labels[-1]\n","\n","combs = []\n","count = 0\n","for patient in patients[0:]:\n","    for phase in sorted(os.listdir(data_path + patient + split + label))[count:]:\n","#         combs.append([patient, phase])\n","        extract_user_features(data_path, patient, split, label, phase, file_name, '5Min')\n","        count += 1\n","# print(combs)\n","# Parallel(n_jobs=4)(delayed(extract_user_features)(data_path, patient, split, label, phase, file_name, frequency='5Min') for patient, phase in combs)"]},{"cell_type":"markdown","metadata":{"id":"vdeNB4jk8B9r"},"source":["## Autoencoder Training"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5307845,"status":"ok","timestamp":1721079260570,"user":{"displayName":"April Yan","userId":"09852906434199162721"},"user_tz":240},"id":"fm4KaEAcPerO","outputId":"6e04b31a-28c7-42a8-d7d1-4b78b1d22d4b"},"outputs":[],"source":["train_mode = 'sleep' # specify CAE tranining data: sleep, awake, or both \n","directory = '../input/'\n","os.chdir(directory) \n","input_list = [f for f in os.listdir() if 'v2' in f]\n","model_name = f'latent_k11_{train_mode}_'  # latent_k{kernel_size}_{status of sleep}\n","norm_cols = ['lin_acc_norm', 'ang_acc_norm',\n","                 'heartRate_mean', 'heartRate_max', 'heartRate_min',\n","                'rRInterval_mean', 'rRInterval_rmssd',\n","          'rRInterval_sdnn', 'rRInterval_sd1', 'rRInterval_sd2',\n","          'rRInterval_lombscargle_power_high', 'rRInterval_lombscargle_power_low']\n","\n","for file_name in input_list:\n","    \n","    df = pd.read_csv(file_name, index_col=0).dropna()\n","    window = 48\n","\n","    X_train, X_val_n, X_val_r = load_data(file_name, norm_cols, window, train_mode)\n","\n","#     tf.random.set_seed(1)\n","    autoencoder = Trainer(X_train, window)\n","    opt = RMSprop(learning_rate=1e-4)\n","    X = np.concatenate([X_train, X_val_n, X_val_r])\n","    X_val = np.concatenate([X_val_n, X_val_r])\n","    autoencoder.compile(optimizer=opt, loss=tf.losses.MeanSquaredError())\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n","    history = autoencoder.fit(X, X,\n","                    epochs=1000,\n","                    batch_size=1,\n","                    # validation_data=[X_val, X_val],\n","                    shuffle=True,\n","                    callbacks=[callback],\n","                    )  # best: 1000, batch = 4, rmsprop validation_data=[X_val_1, X_val_1]\n","\n","    autoencoder.save(f\"../save_model/{model_name}{file_name[-6:-4]}.keras\")"]},{"cell_type":"markdown","metadata":{},"source":["## Clustering and Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_dir = '../input/'\n","model_dir = '../save_model/'\n","test_dir = '../test/'\n","n_range = sorted(os.listdir(data_dir))\n","train_mode, eval_mode = 'sleep', 'both' # e.g., \"sleep\",\"sleep\"; \"awake\",\"both\"\n","\n","auprc_list, auroc_list, auprc_base_list, f1_list, pred_list, true_list = [], [], [], [], [], []\n","for i in range(n_range):\n","  data_file = data_dir + f'input_v2_user0{i}.csv'\n","  model_path = model_dir + f'latent_k11_{train_mode}_0{i}.keras'\n","  test_file = test_dir + f'test_v2_user0{i}.csv'\n","  save_dir = f'./result_6415_concat_k11_{train_mode}_{eval_mode}.csv'\n","  auprc, auroc, auprc_base, f1, y_pred, y_true  = generate_evaluation_result(data_dir, model_dir, test_dir, data_file, model_path, test_file, train_mode, eval_mode)\n","  auprc_list.append(auprc)\n","  auroc_list.append(auroc)\n","  auprc_base_list.append(auprc_base)\n","  f1_list.append(f1)\n","  pred_list.append(y_pred)\n","  true_list.append(y_true)\n","\n","result_df = pd.DataFrame(data={'auprc': auprc_list, 'auroc': auroc_list, 'auprc_base': auprc_base_list,\n","                            'f1': f1_list, 'pred': pred_list, 'y_true':true_list})\n","result_df.to_csv(save_dir) "]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNFoU2iCk8t8bO2NBIWvC50","collapsed_sections":["YuQJXgtOB82k","OHEUuoHXHF55"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
